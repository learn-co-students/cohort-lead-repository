{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 3 Code Challenge: Quality Assurance\n",
    "\n",
    "The following analysis is intended to help a manufacturer avoid sending flawed parts to its customers.  They have provided a CSV dataset with past information about parts that have been flawed as well as parts that have not been flawed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score, plot_confusion_matrix, confusion_matrix, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quality_assurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flawed</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>...</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.517830</td>\n",
       "      <td>0.643975</td>\n",
       "      <td>0.640322</td>\n",
       "      <td>5269</td>\n",
       "      <td>3596.240435</td>\n",
       "      <td>7.582301</td>\n",
       "      <td>5.036856</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>88</td>\n",
       "      <td>67</td>\n",
       "      <td>28</td>\n",
       "      <td>1486.086217</td>\n",
       "      <td>221.448720</td>\n",
       "      <td>914.016198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658969</td>\n",
       "      <td>0.381051</td>\n",
       "      <td>0.711291</td>\n",
       "      <td>0.622806</td>\n",
       "      <td>2529</td>\n",
       "      <td>3915.484661</td>\n",
       "      <td>6.889634</td>\n",
       "      <td>5.463186</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>1041.388025</td>\n",
       "      <td>1012.210842</td>\n",
       "      <td>736.427250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.829151</td>\n",
       "      <td>0.482311</td>\n",
       "      <td>0.695828</td>\n",
       "      <td>0.501425</td>\n",
       "      <td>3466</td>\n",
       "      <td>4938.989252</td>\n",
       "      <td>5.357629</td>\n",
       "      <td>8.479336</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>84</td>\n",
       "      <td>40</td>\n",
       "      <td>1080.024168</td>\n",
       "      <td>1177.252577</td>\n",
       "      <td>1350.203054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.427164</td>\n",
       "      <td>0.302467</td>\n",
       "      <td>0.755639</td>\n",
       "      <td>0.623017</td>\n",
       "      <td>4637</td>\n",
       "      <td>5132.544164</td>\n",
       "      <td>4.607738</td>\n",
       "      <td>6.512086</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>558.167997</td>\n",
       "      <td>1426.797103</td>\n",
       "      <td>497.986919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455892</td>\n",
       "      <td>0.511045</td>\n",
       "      <td>0.834741</td>\n",
       "      <td>0.746559</td>\n",
       "      <td>2283</td>\n",
       "      <td>5652.261077</td>\n",
       "      <td>5.092637</td>\n",
       "      <td>5.744862</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>30</td>\n",
       "      <td>244.940104</td>\n",
       "      <td>1090.685747</td>\n",
       "      <td>178.180980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   flawed         A         B         C         D     E            F  \\\n",
       "0       0  0.601453  0.517830  0.643975  0.640322  5269  3596.240435   \n",
       "1       0  0.658969  0.381051  0.711291  0.622806  2529  3915.484661   \n",
       "2       0  0.829151  0.482311  0.695828  0.501425  3466  4938.989252   \n",
       "3       0  0.427164  0.302467  0.755639  0.623017  4637  5132.544164   \n",
       "4       0  0.455892  0.511045  0.834741  0.746559  2283  5652.261077   \n",
       "\n",
       "          G         H  I  ...   Q   R   S   T   U   V   W            X  \\\n",
       "0  7.582301  5.036856  6  ...  13  27  49  99  88  67  28  1486.086217   \n",
       "1  6.889634  5.463186  5  ...   3  25  66  93   5  84   7  1041.388025   \n",
       "2  5.357629  8.479336  5  ...  95   0  14  67  97  84  40  1080.024168   \n",
       "3  4.607738  6.512086  4  ...  58  56  39   3  19  36  37   558.167997   \n",
       "4  5.092637  5.744862  4  ...  18   6  49  14   4  81  30   244.940104   \n",
       "\n",
       "             Y            Z  \n",
       "0   221.448720   914.016198  \n",
       "1  1012.210842   736.427250  \n",
       "2  1177.252577  1350.203054  \n",
       "3  1426.797103   497.986919  \n",
       "4  1090.685747   178.180980  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flawed</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>...</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.537038</td>\n",
       "      <td>0.424720</td>\n",
       "      <td>0.460606</td>\n",
       "      <td>0.520968</td>\n",
       "      <td>4878.526000</td>\n",
       "      <td>4838.623566</td>\n",
       "      <td>5.574845</td>\n",
       "      <td>5.802130</td>\n",
       "      <td>3.738000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>49.050000</td>\n",
       "      <td>48.224000</td>\n",
       "      <td>48.838000</td>\n",
       "      <td>50.88800</td>\n",
       "      <td>51.240000</td>\n",
       "      <td>48.508000</td>\n",
       "      <td>735.158720</td>\n",
       "      <td>743.363251</td>\n",
       "      <td>746.718788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.406283</td>\n",
       "      <td>0.146943</td>\n",
       "      <td>0.146579</td>\n",
       "      <td>0.193812</td>\n",
       "      <td>0.169511</td>\n",
       "      <td>1761.392433</td>\n",
       "      <td>1719.163590</td>\n",
       "      <td>1.587353</td>\n",
       "      <td>1.431474</td>\n",
       "      <td>1.737641</td>\n",
       "      <td>...</td>\n",
       "      <td>29.135858</td>\n",
       "      <td>29.475568</td>\n",
       "      <td>28.119161</td>\n",
       "      <td>28.799002</td>\n",
       "      <td>29.60724</td>\n",
       "      <td>28.610199</td>\n",
       "      <td>30.109585</td>\n",
       "      <td>428.418133</td>\n",
       "      <td>439.706532</td>\n",
       "      <td>417.469840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311943</td>\n",
       "      <td>0.474553</td>\n",
       "      <td>3.113954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447413</td>\n",
       "      <td>0.328684</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.419994</td>\n",
       "      <td>3778.250000</td>\n",
       "      <td>3570.091136</td>\n",
       "      <td>4.605696</td>\n",
       "      <td>4.991045</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.75000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>358.761812</td>\n",
       "      <td>369.037255</td>\n",
       "      <td>403.933511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535245</td>\n",
       "      <td>0.427028</td>\n",
       "      <td>0.451957</td>\n",
       "      <td>0.530447</td>\n",
       "      <td>4847.500000</td>\n",
       "      <td>4812.028743</td>\n",
       "      <td>5.672153</td>\n",
       "      <td>5.859914</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>52.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>750.787234</td>\n",
       "      <td>719.556908</td>\n",
       "      <td>737.401755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629977</td>\n",
       "      <td>0.520857</td>\n",
       "      <td>0.611244</td>\n",
       "      <td>0.638043</td>\n",
       "      <td>5905.750000</td>\n",
       "      <td>5952.097299</td>\n",
       "      <td>6.588030</td>\n",
       "      <td>6.747137</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>69.250000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>77.00000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1092.726302</td>\n",
       "      <td>1133.751316</td>\n",
       "      <td>1090.111319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1499.126271</td>\n",
       "      <td>1495.460940</td>\n",
       "      <td>1496.597411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           flawed           A           B           C           D  \\\n",
       "count  500.000000  500.000000  475.000000  500.000000  500.000000   \n",
       "mean     0.208000    0.537038    0.424720    0.460606    0.520968   \n",
       "std      0.406283    0.146943    0.146579    0.193812    0.169511   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.447413    0.328684    0.313340    0.419994   \n",
       "50%      0.000000    0.535245    0.427028    0.451957    0.530447   \n",
       "75%      0.000000    0.629977    0.520857    0.611244    0.638043   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "                  E             F           G           H           I  ...  \\\n",
       "count    500.000000    500.000000  500.000000  500.000000  500.000000  ...   \n",
       "mean    4878.526000   4838.623566    5.574845    5.802130    3.738000  ...   \n",
       "std     1761.392433   1719.163590    1.587353    1.431474    1.737641  ...   \n",
       "min        0.000000      0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%     3778.250000   3570.091136    4.605696    4.991045    3.000000  ...   \n",
       "50%     4847.500000   4812.028743    5.672153    5.859914    4.000000  ...   \n",
       "75%     5905.750000   5952.097299    6.588030    6.747137    5.000000  ...   \n",
       "max    10000.000000  10000.000000   10.000000   10.000000   10.000000  ...   \n",
       "\n",
       "                Q           R           S           T          U           V  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.00000  500.000000   \n",
       "mean    49.540000   49.050000   48.224000   48.838000   50.88800   51.240000   \n",
       "std     29.135858   29.475568   28.119161   28.799002   29.60724   28.610199   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.00000    0.000000   \n",
       "25%     23.000000   23.000000   24.000000   24.000000   24.75000   27.000000   \n",
       "50%     52.000000   47.000000   47.000000   49.000000   52.00000   50.000000   \n",
       "75%     74.000000   77.000000   69.250000   74.000000   77.00000   77.000000   \n",
       "max     99.000000   99.000000   99.000000   99.000000   99.00000   99.000000   \n",
       "\n",
       "                W            X            Y            Z  \n",
       "count  500.000000   500.000000   500.000000   500.000000  \n",
       "mean    48.508000   735.158720   743.363251   746.718788  \n",
       "std     30.109585   428.418133   439.706532   417.469840  \n",
       "min      0.000000     0.311943     0.474553     3.113954  \n",
       "25%     22.000000   358.761812   369.037255   403.933511  \n",
       "50%     47.000000   750.787234   719.556908   737.401755  \n",
       "75%     76.000000  1092.726302  1133.751316  1090.111319  \n",
       "max     99.000000  1499.126271  1495.460940  1496.597411  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.792\n",
       "1    0.208\n",
       "Name: flawed, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flawed.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"flawed\", axis=1)\n",
    "y = df[\"flawed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "First, remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     0\n",
       "B    10\n",
       "C     0\n",
       "D     0\n",
       "E     0\n",
       "F     0\n",
       "G     0\n",
       "H     0\n",
       "I     0\n",
       "J     0\n",
       "K     0\n",
       "L     0\n",
       "M     0\n",
       "N     0\n",
       "O     0\n",
       "P     0\n",
       "Q     0\n",
       "R     0\n",
       "S     0\n",
       "T     0\n",
       "U     0\n",
       "V     0\n",
       "W     0\n",
       "X     0\n",
       "Y     0\n",
       "Z     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer()\n",
    "imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0\n",
       "B    0\n",
       "C    0\n",
       "D    0\n",
       "E    0\n",
       "F    0\n",
       "G    0\n",
       "H    0\n",
       "I    0\n",
       "J    0\n",
       "K    0\n",
       "L    0\n",
       "M    0\n",
       "N    0\n",
       "O    0\n",
       "P    0\n",
       "Q    0\n",
       "R    0\n",
       "S    0\n",
       "T    0\n",
       "U    0\n",
       "V    0\n",
       "W    0\n",
       "X    0\n",
       "Y    0\n",
       "Z    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that missing values are filled in, apply scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>...</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.182195</td>\n",
       "      <td>2.651329</td>\n",
       "      <td>2.307228</td>\n",
       "      <td>-1.330215</td>\n",
       "      <td>2.254339</td>\n",
       "      <td>-0.950211</td>\n",
       "      <td>-1.362018</td>\n",
       "      <td>-2.170987</td>\n",
       "      <td>0.159503</td>\n",
       "      <td>-0.407499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.764205</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.057104</td>\n",
       "      <td>-0.935030</td>\n",
       "      <td>-0.210706</td>\n",
       "      <td>1.129001</td>\n",
       "      <td>-0.871019</td>\n",
       "      <td>-1.598601</td>\n",
       "      <td>-1.021046</td>\n",
       "      <td>1.671527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.740476</td>\n",
       "      <td>-0.872133</td>\n",
       "      <td>-1.371398</td>\n",
       "      <td>-0.411639</td>\n",
       "      <td>0.308575</td>\n",
       "      <td>-1.139487</td>\n",
       "      <td>0.085361</td>\n",
       "      <td>0.083841</td>\n",
       "      <td>-2.119116</td>\n",
       "      <td>0.160576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.496621</td>\n",
       "      <td>0.741661</td>\n",
       "      <td>-1.036529</td>\n",
       "      <td>1.044788</td>\n",
       "      <td>1.192936</td>\n",
       "      <td>-0.869210</td>\n",
       "      <td>-0.027706</td>\n",
       "      <td>1.708830</td>\n",
       "      <td>0.574757</td>\n",
       "      <td>-0.871336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.025230</td>\n",
       "      <td>-0.630418</td>\n",
       "      <td>1.154322</td>\n",
       "      <td>-0.255331</td>\n",
       "      <td>-2.506833</td>\n",
       "      <td>-0.080195</td>\n",
       "      <td>-1.958433</td>\n",
       "      <td>1.840817</td>\n",
       "      <td>0.729158</td>\n",
       "      <td>1.296726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216126</td>\n",
       "      <td>1.547913</td>\n",
       "      <td>1.468244</td>\n",
       "      <td>-0.205623</td>\n",
       "      <td>0.987525</td>\n",
       "      <td>1.129001</td>\n",
       "      <td>-0.061438</td>\n",
       "      <td>-1.490713</td>\n",
       "      <td>-0.943989</td>\n",
       "      <td>-0.811323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.636794</td>\n",
       "      <td>-0.141748</td>\n",
       "      <td>-0.953326</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>-0.394256</td>\n",
       "      <td>-1.380725</td>\n",
       "      <td>-0.314150</td>\n",
       "      <td>-0.267118</td>\n",
       "      <td>0.159503</td>\n",
       "      <td>-0.407499</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428111</td>\n",
       "      <td>-1.408342</td>\n",
       "      <td>0.656838</td>\n",
       "      <td>1.183722</td>\n",
       "      <td>-0.450352</td>\n",
       "      <td>-0.518647</td>\n",
       "      <td>-0.230101</td>\n",
       "      <td>0.698315</td>\n",
       "      <td>0.205386</td>\n",
       "      <td>-0.849349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.210566</td>\n",
       "      <td>-0.292733</td>\n",
       "      <td>-0.204884</td>\n",
       "      <td>0.606984</td>\n",
       "      <td>1.883967</td>\n",
       "      <td>0.680080</td>\n",
       "      <td>0.943868</td>\n",
       "      <td>0.269622</td>\n",
       "      <td>0.159503</td>\n",
       "      <td>0.728651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057914</td>\n",
       "      <td>1.413537</td>\n",
       "      <td>1.291851</td>\n",
       "      <td>1.183722</td>\n",
       "      <td>-0.895410</td>\n",
       "      <td>-0.413478</td>\n",
       "      <td>0.275887</td>\n",
       "      <td>1.362921</td>\n",
       "      <td>-0.467244</td>\n",
       "      <td>-1.651644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E         F         G  \\\n",
       "0 -0.182195  2.651329  2.307228 -1.330215  2.254339 -0.950211 -1.362018   \n",
       "1 -0.740476 -0.872133 -1.371398 -0.411639  0.308575 -1.139487  0.085361   \n",
       "2 -2.025230 -0.630418  1.154322 -0.255331 -2.506833 -0.080195 -1.958433   \n",
       "3 -0.636794 -0.141748 -0.953326  0.006883 -0.394256 -1.380725 -0.314150   \n",
       "4 -1.210566 -0.292733 -0.204884  0.606984  1.883967  0.680080  0.943868   \n",
       "\n",
       "          H         I         J  ...         Q         R         S         T  \\\n",
       "0 -2.170987  0.159503 -0.407499  ... -0.764205  0.002598  0.057104 -0.935030   \n",
       "1  0.083841 -2.119116  0.160576  ...  1.496621  0.741661 -1.036529  1.044788   \n",
       "2  1.840817  0.729158  1.296726  ... -0.216126  1.547913  1.468244 -0.205623   \n",
       "3 -0.267118  0.159503 -0.407499  ...  1.428111 -1.408342  0.656838  1.183722   \n",
       "4  0.269622  0.159503  0.728651  ...  0.057914  1.413537  1.291851  1.183722   \n",
       "\n",
       "          U         V         W         X         Y         Z  \n",
       "0 -0.210706  1.129001 -0.871019 -1.598601 -1.021046  1.671527  \n",
       "1  1.192936 -0.869210 -0.027706  1.708830  0.574757 -0.871336  \n",
       "2  0.987525  1.129001 -0.061438 -1.490713 -0.943989 -0.811323  \n",
       "3 -0.450352 -0.518647 -0.230101  0.698315  0.205386 -0.849349  \n",
       "4 -0.895410 -0.413478  0.275887  1.362921 -0.467244 -1.651644  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Now that the data has been prepared for modeling, let's try a `LogisticRegression` model with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = LogisticRegression(random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate based on `recall_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78787879, 0.83870968, 0.73333333, 0.62068966, 0.66666667])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(first_model, X_train, y_train, scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_model.fit(X_train, y_train)\n",
    "plot_confusion_matrix(first_model, X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a different solver with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = LogisticRegression(solver=\"liblinear\", penalty=\"l1\", random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76470588, 0.86666667, 0.75      , 0.62068966, 0.71428571])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(second_model, X_train, y_train, scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "second_model.fit(X_train, y_train)\n",
    "plot_confusion_matrix(second_model, X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model performed better on the cross-validated data for 3/5 of the folds, and slightly worse on the training data.  This indicates that we are preventing some overfitting by switching to using an L1 penalty.  Therefore I choose the second model as my final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Now that I have a final model, I will demonstrate its performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression(solver=\"liblinear\", penalty=\"l1\")\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076923076923077"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, final_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, final_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94,  6],\n",
       "       [ 4, 21]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, final_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1     25\n",
       "Name: flawed, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score of our final model is 0.81 which indicates that the model is performing moderately well on both precision and recall. The recall score of our final model is 0.84, which means that we are correctly flagging 84% of the parts with manufacturing flaws.  So, for the test set, that would mean that we correctly flagged 21 of the 24 flawed parts.  Assuming the previous baseline was 0%, this is a substantial improvement, and I recommend putting this model into production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.23371626842234144,\n",
       " 'B': -0.2190914245429601,\n",
       " 'C': -0.47137677989303495,\n",
       " 'D': -0.6019961922836139,\n",
       " 'E': 2.6976459889651547,\n",
       " 'F': 0.367819602349197,\n",
       " 'G': -0.9302402645306672,\n",
       " 'H': -0.2324573632008139,\n",
       " 'I': -0.011219343498442365,\n",
       " 'J': 0.35588268350772023,\n",
       " 'K': 0.015518539135526043,\n",
       " 'L': 0.09468759433571373,\n",
       " 'M': 0.03629344877661394,\n",
       " 'N': -0.006283223162228509,\n",
       " 'O': 0.1290554314927846,\n",
       " 'P': 0.27423697968030225,\n",
       " 'Q': 0.0,\n",
       " 'R': 0.14034949802649305,\n",
       " 'S': 0.04288598271703693,\n",
       " 'T': 0.1861908030334729,\n",
       " 'U': -0.797935394805448,\n",
       " 'V': -0.15290435489597454,\n",
       " 'W': -0.24891444555341652,\n",
       " 'X': -0.24705631436960077,\n",
       " 'Y': 0.0,\n",
       " 'Z': 0.0682534866257052}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(X_train.columns, final_model.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the magnitude of the coefficient, the less impact the feature has on our predictions.  The coefficients for feature `'Q'` and feature `'Y'` have been reduced to zero by regularization, meaning they have no impact on the current predictions, so those would be good candidates to no longer be collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: More Complex Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76470588, 0.86666667, 0.75      , 0.62068966, 0.71428571])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_scores = cross_val_score(final_model, X_train, y_train, scoring=f1_scorer)\n",
    "logreg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82758621, 0.74074074, 0.81481481, 0.68965517, 0.72      ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "rfc_scores = cross_val_score(random_forest, X_train, y_train, scoring=f1_scorer)\n",
    "rfc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.66666667, 0.47619048, 0.45454545, 0.43478261])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_scores = cross_val_score(knn, X_train, y_train, scoring=f1_scorer)\n",
    "knn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Classifier model performs better than our final Logistic Regression model on 4/5 cross validated folds. So I choose the Random Forest Model and the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.fit(X_train, y_train)\n",
    "preds = random_forest.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100,   0],\n",
       "       [  6,  19]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, random_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performance may not be optimal for my employer's needs. While this model has a higher f1_score, the random forest model has a recall score 8% points lower than final Logistic Regression Model. This model appears to be overfit on the `0` class of these data. Future work could involve adjusting parameters for the Random Forest model to improve performance on the `1` class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
