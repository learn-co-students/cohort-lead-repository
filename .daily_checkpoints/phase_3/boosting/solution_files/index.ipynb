{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## 1. What are two major differences between bagging and boosting?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "# One major distinction is that the learners in a bagging model are trained\n", "# simultaneously and independently, while boosting trains learners iteratively.\n", "\n", "# Relatedly, the bagged learners are strong learners, while boosting begins\n", "# with a weak learner and aims to improve it.\n", "\n", "# The final predictions for a bagged model come from a simple average over\n", "# the individual learners, while, in a boosting model, the learners that\n", "# get unusually correct predictions are accorded more weight."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Gradient Boosting in Scikit-Learn"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Fit a gradient-booster to `X_train_dums` with the following parameters:\n", "- verbose=1\n", "- learning_rate=0.2\n", "- random_state=42"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [], "source": ["\n", "boost = GradientBoostingClassifier(verbose=1, random_state=42, learning_rate=0.2)\n", "\n", "boost.fit(X_train_dums, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. What does the printout tell us?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "# The printout shows the iteration count, the training error for the learner at\n", "# that iteration, and the time remaining for the training run. The training\n", "# loss decreases at every iteration, which is a sign that the boosting is\n", "# working."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Calculate and interpret the F-1 score for this model."]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": ["\n", "from sklearn.metrics import f1_score\n", "f1_score(y_test, boost.predict(X_test_dums))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "# The F-1 score is the harmonic mean of the precision and the recall.\n", "# A score of 0.5 means that the sum of false positive and false negatives\n", "# outnumber the true positives 2:1. So a score of 0.6 is pretty good."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. What does the code below do? And what does it tell us about the model's predictions for Haitians?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "# The code first adds actual and predicted values (for salary > $50k) to the test data.\n", "# Then it isolates the records from Haiti and compares the actual to the predicted values.\n", "# The fact that `haiti['diff'].sum() / len(haiti)` = 1 means that the model correctly\n", "# predicted the target for all Haitians."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 2}