{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Logistic Regression"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import itertools\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns\n", "import numpy as np\n", "from sklearn.linear_model import Lasso, Ridge\n", "import pickle\n", "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1) Why is logistic regression typically better than linear regression for modeling a binary target/outcome?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\"\"\"\n", "Your written answer here\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {"jupyter": {"source_hidden": true}}, "source": ["<!---\n", "# load data\n", "ads_df = pd.read_csv(\"raw_data/social_network_ads.csv\")\n", "\n", "# one hot encode categorical feature\n", "def is_female(x):\n", "    \"\"\"Returns 1 if Female; else 0\"\"\"\n", "    if x == \"Female\":\n", "        return 1\n", "    else:\n", "        return 0\n", "        \n", "ads_df[\"Female\"] = ads_df[\"Gender\"].apply(is_female)\n", "ads_df.drop([\"User ID\", \"Gender\"], axis=1, inplace=True)\n", "ads_df.head()\n", "\n", "# separate features and target\n", "X = ads_df.drop(\"Purchased\", axis=1)\n", "y = ads_df[\"Purchased\"]\n", "\n", "# train/test split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=19)\n", "\n", "# preprocessing\n", "scale = StandardScaler()\n", "scale.fit(X_train)\n", "X_train = scale.transform(X_train)\n", "X_test = scale.transform(X_test)\n", "\n", "# save preprocessed train/test split objects\n", "pickle.dump(X_train, open(\"write_data/social_network_ads/X_train_scaled.pkl\", \"wb\"))\n", "pickle.dump(X_test, open(\"write_data/social_network_ads/X_test_scaled.pkl\", \"wb\"))\n", "pickle.dump(y_train, open(\"write_data/social_network_ads/y_train.pkl\", \"wb\"))\n", "pickle.dump(y_test, open(\"write_data/social_network_ads/y_test.pkl\", \"wb\"))\n", "\n", "# build model\n", "model = LogisticRegression(C=1e5, solver=\"lbfgs\")\n", "model.fit(X_train, y_train)\n", "y_test_pred = model.predict(X_test)\n", "y_train_pred = model.predict(X_train)\n", "\n", "from sklearn.metrics import confusion_matrix\n", "\n", "# create confusion matrix\n", "# tn, fp, fn, tp\n", "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n", "cnf_matrix\n", "\n", "# build confusion matrix plot\n", "plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) #Create the basic matrix.\n", "\n", "# Add title and Axis Labels\n", "plt.title('Confusion Matrix')\n", "plt.ylabel('True label')\n", "plt.xlabel('Predicted label')\n", "\n", "# Add appropriate Axis Scales\n", "class_names = set(y_test) #Get class labels to add to matrix\n", "tick_marks = np.arange(len(class_names))\n", "plt.xticks(tick_marks, class_names)\n", "plt.yticks(tick_marks, class_names)\n", "\n", "# Add Labels to Each Cell\n", "thresh = cnf_matrix.max() / 2. #Used for text coloring below\n", "#Here we iterate through the confusion matrix and append labels to our visualization.\n", "for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n", "        plt.text(j, i, cnf_matrix[i, j],\n", "                 horizontalalignment=\"center\",\n", "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n", "\n", "# Add a Side Bar Legend Showing Colors\n", "plt.colorbar()\n", "\n", "# Add padding\n", "plt.tight_layout()\n", "plt.savefig(\"visuals/cnf_matrix.png\",\n", "            dpi=150,\n", "            bbox_inches=\"tight\")\n", "--->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![cnf matrix](visuals/cnf_matrix.png)\n", "\n", "### 2) Using the confusion matrix above, calculate precision, recall, and F-1 score.\n", "Show your work, not just your final numeric answer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here to calculate precision"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here to calculate recall"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here to calculate F-1 score"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3)  What is a real life example of when you would care more about recall than precision? Make sure to include information about errors in your explanation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\"\"\"\n", "Your written answer here\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!---\n", "# save preprocessed train/test split objects\n", "X_train = pickle.load(open(\"write_data/social_network_ads/X_train_scaled.pkl\", \"rb\"))\n", "X_test = pickle.load(open(\"write_data/social_network_ads/X_test_scaled.pkl\", \"rb\"))\n", "y_train = pickle.load(open(\"write_data/social_network_ads/y_train.pkl\", \"rb\"))\n", "y_test = pickle.load(open(\"write_data/social_network_ads/y_test.pkl\", \"rb\"))\n", "\n", "# build model\n", "model = LogisticRegression(C=1e5, solver=\"lbfgs\")\n", "model.fit(X_train, y_train)\n", "y_test_pred = model.predict(X_test)\n", "y_train_pred = model.predict(X_train)\n", "\n", "labels = [\"Age\", \"Estimated Salary\", \"Female\", \"All Features\"]\n", "colors = sns.color_palette(\"Set2\")\n", "plt.figure(figsize=(10, 8))\n", "# add one ROC curve per feature\n", "for feature in range(3):\n", "    # female feature is one hot encoded so it produces an ROC point rather than a curve\n", "    # for this reason, female will not be included in the plot at all since it is\n", "    # disingeneuous to call it a curve.\n", "    if feature == 2:\n", "        pass\n", "    else:\n", "        X_train_feat = X_train[:, feature].reshape(-1, 1)\n", "        X_test_feat = X_test[:, feature].reshape(-1, 1)\n", "        logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='lbfgs')\n", "        model_log = logreg.fit(X_train_feat, y_train)\n", "        y_score = model_log.decision_function(X_test_feat)\n", "        fpr, tpr, thresholds = roc_curve(y_test, y_score)\n", "        lw = 2\n", "        plt.plot(fpr, tpr, color=colors[feature],\n", "                 lw=lw, label=labels[feature])\n", "\n", "# add one ROC curve with all the features\n", "model_log = logreg.fit(X_train, y_train)\n", "y_score = model_log.decision_function(X_test)\n", "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n", "lw = 2\n", "plt.plot(fpr, tpr, color=colors[3], lw=lw, label=labels[3])\n", "\n", "# create foundation of the plot\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.yticks([i / 20.0 for i in range(21)])\n", "plt.xticks([i / 20.0 for i in range(21)])\n", "plt.xlabel(\"False positive rate\")\n", "plt.ylabel(\"True positive rate\")\n", "plt.title(\"ROC Curve\")\n", "plt.legend()\n", "plt.tight_layout()\n", "plt.savefig(\"visuals/many_roc.png\",\n", "            dpi=150,\n", "            bbox_inches=\"tight\")\n", "--->"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img src = \"visuals/many_roc.png\" width = \"700\">\n", "\n", "### 4) Which ROC curve from the above graph is the best? Explain your reasoning.\n", "\n", "Note: each ROC curve represents one model, each labeled with the feature(s) inside each model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\"\"\"\n", "Your written answer here\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Logistic Regression Example\n", "\n", "The following cell includes code to train and evaluate a model"]}, {"cell_type": "markdown", "metadata": {"jupyter": {"source_hidden": true}}, "source": ["<!---\n", "# sorting by 'Purchased' and then dropping the last 130 records\n", "dropped_df = ads_df.sort_values(by=\"Purchased\")[:-130]\n", "dropped_df.reset_index(inplace=True)\n", "pickle.dump(dropped_df, open(\"write_data/sample_network_data.pkl\", \"wb\"))\n", "--->"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "network_df = pickle.load(open('write_data/sample_network_data.pkl', 'rb'))\n", "\n", "# partion features and target \n", "X = network_df.drop('Purchased', axis=1)\n", "y = network_df['Purchased']\n", "\n", "# train test split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)\n", "\n", "# scale features\n", "scale = StandardScaler()\n", "scale.fit(X_train)\n", "X_train = scale.transform(X_train)\n", "X_test = scale.transform(X_test)\n", "\n", "# build classifier\n", "model = LogisticRegression(C=1e5, solver='lbfgs')\n", "model.fit(X_train, y_train)\n", "y_test_pred = model.predict(X_test)\n", "\n", "# get the accuracy score\n", "print(f'The classifier has an accuracy score of {round(accuracy_score(y_test, y_test_pred), 3)}.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 5) The model above has an accuracy score that might be too good to believe. Using `y.value_counts()`, explain how `y` is affecting the accuracy score."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "y.value_counts()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\"\"\"\n", "Your written answer here\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 6) What is one method you could use to improve your model to address the issue discovered in Question 5?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\"\"\"\n", "Your written answer here\n", "\"\"\""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 4}