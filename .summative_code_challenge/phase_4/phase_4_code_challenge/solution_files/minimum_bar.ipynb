{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This is a notebook designed to demonstrate the \"minimum bar\" for passing.  Basically it is a student who is able to cobble together the code from the `product_review_classification` notebook + the code from the TensorFlow checkpoint, and change the input shape of the sequential model._\n",
    "\n",
    "_It is truly supposed to be a \"minimum bar\" and the rubric is calibrated so this student should get 50%, the passing grade._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Review Classification\n",
    "\n",
    "## Business Understanding\n",
    "Our company wants a tool that will automatically classify product reviews as _positive_ or _negative_ reviews, based on the features of the review.  This will help our Product team to perform more sophisticated analyses in the future to help ensure customer satisfaction.\n",
    "\n",
    "## Data Understanding\n",
    "We have a labeled collection of 20,000 product reviews, with an equal split of positive and negative reviews. The dataset contains the following features:\n",
    "\n",
    " - `ProductId` Unique identifier for the product\n",
    " - `UserId` Unqiue identifier for the user\n",
    " - `ProfileName` Profile name of the user\n",
    " - `HelpfulnessNumerator` Number of users who found the review helpful\n",
    " - `HelpfulnessDenominator` Number of users who indicated whether they found the review helpful or not\n",
    " - `Time` Timestamp for the review\n",
    " - `Summary` Brief summary of the review\n",
    " - `Text` Text of the review\n",
    " - `PositiveReview` 1 if this was labeled as a positive review, 0 if it was labeled as a negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>PositiveReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B002QWHJOU</td>\n",
       "      <td>A37565LZHTG1VH</td>\n",
       "      <td>C. Maltese</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1305331200</td>\n",
       "      <td>Awesome!</td>\n",
       "      <td>This is a great product. My 2 year old Golden ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000ESLJ6C</td>\n",
       "      <td>AMUAWXDJHE4D2</td>\n",
       "      <td>angieseashore</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1320710400</td>\n",
       "      <td>Was there a recipe change?</td>\n",
       "      <td>I have been drinking Pero ever since I was a l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004IJJQK4</td>\n",
       "      <td>AMHHNAFJ9L958</td>\n",
       "      <td>A M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1321747200</td>\n",
       "      <td>These taste so bland.</td>\n",
       "      <td>Look, each pack contains two servings of 120 c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId    ProfileName  HelpfulnessNumerator  \\\n",
       "0  B002QWHJOU  A37565LZHTG1VH     C. Maltese                     1   \n",
       "1  B000ESLJ6C   AMUAWXDJHE4D2  angieseashore                     1   \n",
       "2  B004IJJQK4   AMHHNAFJ9L958            A M                     0   \n",
       "\n",
       "   HelpfulnessDenominator        Time                     Summary  \\\n",
       "0                       1  1305331200                    Awesome!   \n",
       "1                       1  1320710400  Was there a recipe change?   \n",
       "2                       1  1321747200       These taste so bland.   \n",
       "\n",
       "                                                Text  PositiveReview  \n",
       "0  This is a great product. My 2 year old Golden ...               1  \n",
       "1  I have been drinking Pero ever since I was a l...               0  \n",
       "2  Look, each pack contains two servings of 120 c...               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has already been cleaned, so there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductId                 0\n",
       "UserId                    0\n",
       "ProfileName               0\n",
       "HelpfulnessNumerator      0\n",
       "HelpfulnessDenominator    0\n",
       "Time                      0\n",
       "Summary                   0\n",
       "Text                      0\n",
       "PositiveReview            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PositiveReview` is the target, and all other columns are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"PositiveReview\", axis=1)\n",
    "y = df[\"PositiveReview\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "First, split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, prepare for modeling. The following `Pipeline` prepares all data for modeling.  It one-hot encodes the `ProductId`, applies a tf-idf vectorizer to the `Summary` and `Text`, keeps the numeric columns as-is, and drops all other columns.\n",
    "\n",
    "The following code may take up to 1 minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 11275)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_irrelevant_columns(X):\n",
    "    return X.drop([\"UserId\", \"ProfileName\"], axis=1)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"drop_columns\", FunctionTransformer(drop_irrelevant_columns)),\n",
    "    (\"transform_text_columns\", ColumnTransformer(transformers=[\n",
    "        (\"ohe\", OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\", sparse=False), [\"ProductId\"]),\n",
    "        (\"summary-tf-idf\", TfidfVectorizer(max_features=1000), \"Summary\"),\n",
    "        (\"text-tf-idf\", TfidfVectorizer(max_features=1000), \"Text\")\n",
    "    ], remainder=\"passthrough\"))\n",
    "])\n",
    "\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Fit a `RandomForestClassifier` with the best hyperparameters.  The following code may take up to 1 minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=30, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=15,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=1\n",
    ")\n",
    "rfc.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We are using _accuracy_ as our metric, which is the default metric in Scikit-Learn, so it is possible to just use the built-in `.score` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9826666666666667\n",
      "Test accuracy: 0.913\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", rfc.score(X_train_transformed, y_train))\n",
    "print(\"Test accuracy:\", rfc.score(X_test_transformed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      "[[7312  177]\n",
      " [  83 7428]]\n",
      "Test confusion matrix:\n",
      "[[2293  218]\n",
      " [ 217 2272]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train confusion matrix:\")\n",
    "print(confusion_matrix(y_train, rfc.predict(X_train_transformed)))\n",
    "print(\"Test confusion matrix:\")\n",
    "print(confusion_matrix(y_test, rfc.predict(X_test_transformed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Interpretation\n",
    "\n",
    "The tuned Random Forest Classifier model appears to be somewhat overfit on the training data, but nevertheless achieves 91% accuracy on the test data.  Of the 9% of mislabeled comments, about half are false positives and half are false negatives.\n",
    "\n",
    "Because this is a balanced dataset, 91% accuracy is a substantial improvement over a 50% baseline.  This model is ready for production use for decision support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This marks the start of the \"student\" code done during the code challenge_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, regularizers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier\n",
    "classifier = Sequential()\n",
    "\n",
    "# add input layer (shape is 300 because X has 300 features)\n",
    "classifier.add(Dense(units=64, input_shape=(11275,)))\n",
    "\n",
    "# add hidden layers\n",
    "classifier.add(Dense(units=64))\n",
    "classifier.add(Dense(units=64))\n",
    "\n",
    "# add output layer\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 6s 385us/sample - loss: 8.0709 - acc: 0.4993\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 5s 324us/sample - loss: 8.0709 - acc: 0.4993\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 5s 315us/sample - loss: 8.0709 - acc: 0.4993\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 5s 303us/sample - loss: 8.0709 - acc: 0.4993\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 4s 299us/sample - loss: 8.0709 - acc: 0.4993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x131d92da0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_transformed, y_train, epochs=5, verbose=1, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5022"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, classifier.predict_classes(X_test_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network is basically performing the same as a coin flip.  \n",
    "\n",
    "It is possible that the network would be able to outperform the Random Forest Classifier with additional preprocessing and tuning, but at this time the performance is quite poor.\n",
    "\n",
    "At this stage we definitely do not suggest switching from using the Random Forest Classifier to using a neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
